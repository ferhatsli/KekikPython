ğŸ•Š Bu dÃ¶kÃ¼man [**@KekikAkademi**](https://t.me/KekikAkademi "Telegram: @KekikAkademi") iÃ§in oluÅŸturulmuÅŸtur. âœŒğŸ¼
________________________________
# Py4H Googler
![Python Google Searcher](https://raw.githubusercontent.com/KekikAkademi/KekikPython/master/5-Py4H-Googler/images/python-google-searcher.jpg)

Merhaba arkadaÅŸlar. BugÃ¼n **Hackerlar iÃ§in Python Programlama Dili** yani **Python4Hackers** diyerek ilk projemizi beraber yapÄ±yor olacaÄŸÄ±z.
BaÅŸlÄ±ktan da anlaÅŸÄ±lacaÄŸÄ± gibi Google arama motorunu kullanan bir searcher projesi yapÄ±yoruz.
Googler, aramak istediÄŸimiz d0rklarÄ± Google Ã¼zerinden arayarak Ã§Ä±kan sonuÃ§larÄ± bize veren bir programdÄ±r.

### **SaldÄ±rÄ± Senaryosu:**
Ã–rneÄŸin Joomlaâ€™nÄ±n X bir eklentisinde SQL Injection zafiyeti tespit edilmiÅŸ ve biz de bu zafiyeti exploit edebilmek iÃ§in X eklentisini kullanan Joomla siteleri Google arama motorunu kullanarak tespit edeceÄŸiz.

### **Algoritma:**
-   BaÅŸla
   -   EÄŸer argÃ¼manlarda â€œ-d,-s,-fâ€ varsa 3. adÄ±ma git, yoksa programdan Ã§Ä±k
   -   ArgÃ¼manlarÄ± -d,-s,-f al
   -   ArgÃ¼manlarÄ± arama() fonksiyonuna gÃ¶nder
   -   -f argÃ¼man deÄŸeriyle dosyayÄ± oluÅŸtur ve aÃ§
   -   i = 0
   -   ss = i+1 ve -d deÄŸeri iÃ§in Googleâ€™a Get isteÄŸi gÃ¶nder
   -   SayfanÄ±n kaynak kodunu al
   -   Kaynak kodu parÃ§ala ve Ã§Ä±kan linkleri al
   -   Ã‡Ä±kan linkleri dosyaya kaydet
   -   i++
   -   EÄŸer i < -s ise 7. adÄ±ma git
   -   DosyayÄ± kapat
   -   print ("\n[-] Ä°ÅŸlem bitmiÅŸtir.. ")
   -   Bitti

### **Kod PaylaÅŸÄ±mÄ±:**
Ä°lk olarak genel ayarlarÄ± yaptÄ±k, kullanacaÄŸÄ±mÄ±z modÃ¼lleri (mechanize, sys, re, HTMLParser, urllib, BeautifulSoup) projemize import ettik ve deÄŸiÅŸken atamalarÄ±mÄ±zÄ± yaptÄ±k:

	import mechanize,sys,re,html.parser,urllib.request,urllib.parse,urllib.error # kullanacaÄŸÄ±mÄ±z modÃ¼ller(kÃ¼tÃ¼phaneler)
	from bs4 import BeautifulSoup # kullanacaÄŸÄ±mÄ±z modÃ¼ller(kÃ¼tÃ¼phaneler)

	h = html.parser.HTMLParser() # HtmlParser metodu iÃ§in referans gÃ¶sterdik
	br = mechanize.Browser() # mechanize Browser metodu iÃ§in referans gÃ¶sterdik
	br.set_handle_robots(False) # robots.txt engellerine yakalanmamak iÃ§in false dedik
	br.addheaders = [('User-agent', 'Mozilla/5.0 (compatible; Konqueror/3.5; Linux) KHTML/3.5.5 (like Gecko) (Kubuntu)')] # tarayÄ±cÄ±mÄ±za header bilgisi ekledik.

**giris** fonksiyonumuzu oluÅŸturduk. **try** ve **except** metodu ile olasÄ± hatalar kullanÄ±cÄ±nÄ±n gÃ¶zÃ¼nden gizlenmek istenmiÅŸtir. Her seferinde kullanÄ±cÄ±nÄ±n programÄ± nasÄ±l kullanacaÄŸÄ±nÄ± gÃ¶stermek iÃ§in de uyarÄ± mesajlarÄ±mÄ±zÄ± eksik etmedik:

	def giris(): # giris fonksiyonumuz
		try:
			if sys.argv[1] == "-d" and sys.argv[3] == "-s" and sys.argv[5] == "-f": #EÄŸer '-d,-s,-f' argÃ¼manlarÄ± var ise
				dork = sys.argv[2] # dorkumuzu aldÄ±k
				sayfa_sayisi = sys.argv[4] # sayfa sayÄ±sÄ±nÄ± aldÄ±k
				dosya_ismi = sys.argv[6] # sonuÃ§larÄ±n kayÄ±t edileceÄŸi dosyamÄ±zÄ± aldÄ±k
				arama(dork,sayfa_sayisi,dosya_ismi) # arama fonksiyonuna gÃ¶nderdik
			else: #argÃ¼manlar yok ise
				print("    >> python googler.py -d /admin.php -s 10 -f cikti.txt \n\n    -d = dork \n    -s = Sayfa sayÄ±sÄ±\n    -f = kaydedilcek dosya ismi")
		except:
			print("    >> python googler.py -d /admin.php -s 10 -f cikti.txt \n\n    -d = dork \n    -s = Sayfa sayÄ±sÄ±\n    -f = kaydedilcek dosya ismi")

AÅŸaÄŸÄ±daki kodlarÄ±mÄ±z **arama fonksiyonu**muza aittir. Burada kaynak kodlarÄ± parÃ§alarken merdiven gibi taglar arasÄ±nda iniÅŸ yaptÄ±m fakat sizler istediÄŸiniz deÄŸerleri almak iÃ§in harika bir **regex** kuralÄ± yazarak tek seferde alabilirsiniz. Her sayfada iÅŸimiz bittikten sonra sÄ±radaki sayfalar iÃ§inde aynÄ± ÅŸeyi yaparak deÄŸerlerimizi Ã§ektik arkadaÅŸlar.

	def arama(dork,sayfa_sayisi,dosya_ismi): # arama fonksiyonumuz ve fonksiyona gelen deÄŸerler
		dosya = open(dosya_ismi,"a") # dosyamÄ±zÄ± aÃ§tÄ±k
		dorks=urllib.parse.quote(dork) #dorkumuzu encode ettik bazÄ± karakterlerden Ã¶tÃ¼rÃ¼ hata vermemesi iÃ§in
		for i in range(0,int(sayfa_sayisi)): # sayfa sayisi kadar dÃ¶nen dÃ¶ngÃ¼mÃ¼z
			ss = i+1 # ss 1 arttÄ±rdÄ±k
			url = "https://www.google.com.tr/search?q=%s&noj=1&start=%s0" %(dorks,i) # url de deÄŸerleri yerine koyduk
			print("[+] %s. Sayfa yazildi.." %ss) # uyarÄ± mesajÄ±mÄ±z
			a = br.open(url) # linkimizi aÃ§tÄ±k
			kodlar = a.read() # kaynak kodlarÄ±mÄ±zÄ± aldÄ±k Ã§Ä±kan sayfadan
			kazan = BeautifulSoup(kodlar) # Ben buna kodlarÄ± kazana atmak diyorum.
			ayiklama = kazan.find_all('h3') # kaynak kodlardan h3 taglarÄ±nÄ± aldÄ±k ve liste olarak kayÄ±t ettik dikkat 'ayiklama' listedir.
			for i in ayiklama: # listemizde ki elemanlarÄ± tek tek dÃ¶kerken
				ayiklama1 = i.find_all('a') # aynÄ± ÅŸekilde dÃ¶kÃ¼len her elemandan a taglarÄ±nÄ± aldÄ±k <a href=''></a> ÅŸeklinde olur..
				#print ayiklama1
				for a in ayiklama1: # a taglarÄ±nÄ± dÃ¶kÃ¼yoruz
					hedef = a.get('href') # a taglarÄ±nÄ±n iÃ§inde ki href deÄŸerlerini aldÄ±k
					l = hedef.lstrip('/url?q=') # deÄŸerlerin solundan birÅŸeyleri kestik attÄ±k.
					f = re.findall('(.*?)&sa',l) # hala istemediÄŸimiz deÄŸerler vardÄ± bu ÅŸekilde son defa re.findall ile basit bir kural belirleyerek istediÄŸimizi aldÄ±k.
					for hedef in f: # son aldÄ±ÄŸÄ±mÄ±z deÄŸerleri dÃ¶kÃ¼yoruz
						asd = h.unescape(urllib.parse.unquote(hedef)) # deÄŸerler html encode halinde ve bazÄ± bozukluklarÄ± var tamir ettik
						dosya.write(asd+"\n") # dosyamÄ±za yazdÄ±rdÄ±k
						#print hedef

[KodlarÄ±n TamamÄ±na Burdan UlaÅŸabilirsiniz!](https://github.com/KekikAkademi/KekikPython/blob/master/5-Py4H-Googler/Py4H-Googler.py)

### **Notlar:**
   -   Projede kullandÄ±ÄŸÄ±mÄ±z mechanize, BeautifulSoup, HtmlParser modÃ¼lleri Pythonâ€™Ä±n sabit modÃ¼lleri olmayÄ±p sizin haricen yÃ¼klemeniz gerekmektedir.

> Bir sonraki yazÄ±mÄ±zda gÃ¶rÃ¼ÅŸmek Ã¼zere.

[Kaynak](http://python4hackers.com/python-search-engine-tools/py4h-googler.html "SaygÄ± ve Ã–zlemle...")
________________________________

ğŸ“ƒ **Yandex.Disk BÃ¼nyemizde 900GB veri olmuÅŸtur.**

_PaylaÅŸÄ±lan KurslarÄ±n TÃ¼mÃ¼nÃ¼_ [**@KekikKahve**](https://t.me/KekikKahve) _Grubu notlarÄ±ndan Ã‡aÄŸÄ±rabilirsiniz.._

ğŸ•Šï¸ Bize **oy verip** _paylaÅŸarak_ destek olmaya ne dersin? âœŒğŸ¼
#
> Bu readme sayfasÄ± oluÅŸturulurken [prose.io](http://prose.io/ "prose.io") ve [stackedit.io](https://stackedit.io/app "stackedit.io") araÃ§larÄ±ndan yardÄ±m alÄ±nmÄ±ÅŸtÄ±r..
> Emojiler iÃ§in [webfx](https://www.webfx.com/tools/emoji-cheat-sheet/ "Emoji Cheat Sheet") sayfasÄ± kullanÄ±lmÄ±ÅŸtÄ±r.
